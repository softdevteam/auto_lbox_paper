\documentclass[sigplan,screen]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{adjustbox}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{mdwlist}
\usepackage{multicol}
\usepackage[autolanguage]{numprint}
\usepackage{proof}
\usepackage{softdev}
\usepackage{stmaryrd}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{xspace}
\usepackage{menukeys}
\usepackage[normalem]{ulem}

\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

%\acmJournal{SLE}
%\acmVolume{1}
%\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
%\acmArticle{1}
%\acmYear{2019}
%\acmMonth{1}
%\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\acmConference[SLE'19]{Software Language Engineering}{October 2019}{Athens, Greece}
\startPage{1}

\lstset{
    basicstyle=\ttfamily\scriptsize,
    xleftmargin=0pt,
    numbersep=.8em,
    numberstyle=\scriptsize\tt\color{gray},
    captionpos=b,
    escapeinside={{<!}{!>}},
}

% from https://tex.stackexchange.com/questions/264361/skipping-line-numbers-in-lstlisting#264373
\let\origthelstnumber\thelstnumber
\makeatletter
\newcommand*\Suppressnumber{%
  \lst@AddToHook{OnNewLine}{%
    \let\thelstnumber\relax%
     \advance\c@lstnumber-\@ne\relax%
    }%
}

\newcommand*\Reactivatenumber[1]{%
  \setcounter{lstnumber}{\numexpr#1-1\relax}
  \lst@AddToHook{OnNewLine}{%
   \let\thelstnumber\origthelstnumber%
   \refstepcounter{lstnumber}
  }%
}

\setcopyright{none}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}

% DOI
%\acmDOI{0000001.0000001}

% Paper history
%\received{February 2007}

\newcommand{\inputtree}[0]{\emph{CST}\xspace}
\newcommand{\eco}[0]{\emph{Eco}\xspace}
\newcommand{\ald}[0]{\emph{ALD}\xspace}
\newcommand{\qtt}[1]{`\texttt{#1}'\xspace}

\newcommand{\hotkeynewlbox}[0]{\keys{Ctrl+L}\xspace}
\newcommand{\hotkeyleavelbox}[0]{\keys{Ctrl+Shift+L}\xspace}

\include{experimentstats}

\lstnewenvironment{lstdefault}[1][]
  {
    \lstset{
        numbers=left,
        language=Python,
        keywordstyle=\color{red!70!black},
        commentstyle=\itshape\color{gray!90!black},
        stringstyle=\color{green!60!black},
        basicstyle=\linespread{0.9}\footnotesize\ttfamily,
        numberstyle=\tiny,
        keepspaces=true,
        breaklines=true,
        captionpos=b,
        abovecaptionskip=0.8em,
        columns=fullflexible,
        xleftmargin=10pt,
        aboveskip=1em,
        belowskip=0em,
        showstringspaces=false,
        literate={\$}{{\$}}1,
        escapeinside={{<!}{!>}},
        #1
    }
}{}

\lstdefinelanguage{EcoGrammar}
{
    alsoletter={:,\:=,|},
    morekeywords={:, =, | },
    keywordstyle=\color{red!70!black},
    morestring=[b]",
    stringstyle=\color{green!60!black},
    commentstyle=\itshape\color{gray!90!black},
    comment=[l]{//},
    morecomment=[s]{/*}{*/},
}

\lstnewenvironment{lsteco}[1][]
  {
    \lstset{
        language=EcoGrammar,
        basicstyle=\footnotesize\ttfamily,
        numberstyle=\tiny,
        xleftmargin=10pt,
        showstringspaces=false,
        #1
    }
}{}

% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title{Automatic Language boxes}

\author{Lukas Diekmann}
\affiliation{%
  \department{Software Development Team}
  \institution{King's College London}
  \country{United Kingdom}}
\author{Laurence Tratt}
\orcid{0000-0002-5258-3805}
\affiliation{%
  \department{Software Development Team}
  \institution{King's College London}
  \country{United Kingdom}
}
\thanks{Authors' URLs: %
    L.~Diekmann~\url{http://lukasdiekmann.com/},
    L.~Tratt~\url{http://tratt.net/laurie/}.
}


\begin{abstract}
Since composed grammars are often ambiguous, grammar composition requires a
mechanism for dealing with ambiguity: either ruling it out entirely through the use of
delimiters, or by selecting the desired parse tree from the parse forest.  In
this paper we show that \emph{language boxes} -- a delimiter-based
algorithm atop incremental parsing -- can be extended in a way that creates
a new point in the design space between these two extremes. In essence, we
retain the use of delimiters, but
introduce an algorithm which provides a default disambiguation scheme that
can automatically insert, remove, or resize
language boxes -- leading to what we call \emph{automatic language
boxes}. The very nature of the problem means that automatic language boxes
cannot always match a user's intention. However, our experimental
evaluation shows that it behaves acceptably in \validalloverall of
tests involving compositions of real-world programming languages.
\end{abstract}

\keywords{Parsing, language composition, programming languages}

\maketitle

\section{Introduction}

\begin{figure*}
    \vspace{1em}
    \includegraphics[width=1.00\textwidth]{images/mainexample_java_sql}
    \begin{picture}(0,0)
        \put(-249,103){\textcolor{black}{\footnotesize\textbf{(a)}}}
        \put(-103,103){\textcolor{black}{\footnotesize\textbf{(b)}}}
        \put(  40,103){\textcolor{black}{\footnotesize\textbf{(c)}}}
        \put(-249,51){\textcolor{black}{\footnotesize\textbf{(d)}}}
        \put(  40,51){\textcolor{black}{\footnotesize\textbf{(e)}}}
    \end{picture}
    \vspace{-2.2em}
    \caption{An example of automatic language boxes in action (with elided screenshots from our
      extension to the Eco editor). Here, the user is entering text in a
      composition of Java and SQL, where SQL statements can be used wherever
      Java expressions are valid. As the user types, language boxes (with a
      pink background) are automatically inserted, removed, or resized.
      \textbf{(a)} After typing the skeleton of a Java function, the user begins
      typing an SQL statement as the right-hand side expression of a Java
      assignment. The most fundamental part of the
      algorithm is to try inserting language boxes when a syntax error in the
      outer language occurs (as can be seen at the \texttt{min} function) but
      not if it then leads to a syntax error immediately after the inserted
      language box. It is thus too early to insert an automatic language box
      around the SQL as it would cause a syntax error in the first non-whitespace token
      afterwards (`\texttt{\}}'). \textbf{(b)} After typing `\texttt{,}' an SQL
      language box is automatically inserted since the next non-whitespace Java token
      (`\texttt{,}') is now syntactically valid. \textbf{(c)} The user continues
      typing a (now incomplete) SQL statement. This causes syntax errors in the
      outer language which cannot yet be resolved by inserting, removing, or
      resizing any language boxes.  \textbf{(d)} After typing `\texttt{;}', the
      automatic language box algorithm resizes the existing language box to
      encompass the entire SQL statement, making the program syntactically
      complete. \textbf{(e)} Further syntactically correct Java input does not
      cause the language box to be altered.
}
\label{intro_example}
\end{figure*}

Language composition -- the ability to build larger languages out of multiple
small languages -- offers an enticing solution to problems such as the
development of domain-specific languages or the migration of legacy software.
Unfortunately, writing and editing composed programs is often cumbersome.
The basic problem is that grammar
composition -- which underpins language composition -- can cause
two provably unambiguous grammars to become ambiguous when composed,
and determining whether a grammar is unambiguous or not is
undecidable~\cite{cantor62ambiguity}. There are two fundamental approaches
of coping with ambiguity: either ruling it out through the use of
delimiters (via explicit bracketing or syntax-directed
editing); or using a generalised parsing algorithm that can create a parse
forest, capturing all ambiguities
(e.g.~\cite{visser97scannerless}). Each has different trade-offs: delimiters
are visually intrusive and/or awkward to work with; and one can never know if all possible
ambiguous parses have been covered by disambiguation operators.

An alternative to traditional delimiter-based approaches are \emph{language boxes} which aim to
combine the advantages of explicit bracketing and syntax-based
editing~\cite{diekmann14eco}. In essence, an editor
which supports language boxes needs to support an incremental parsing algorithm
(we assume that of~\citet{wagner98practicalalgorithms}), which provides an
online editing experience: unlike traditional editors, users do not directly edit
a contiguous block of text in memory, but instead
indirectly edit a parse tree, which is continuously updated as they type.
A language box is then simply a node in the parse
tree that represent a different language, surrounded by
explicit, but invisible, delimiters. Unlike explicit bracketing approaches,
there are no visually intrusive delimiters; unlike traditional
syntax-based editors, the program can be syntactically incorrect in arbitrary
ways and places during editing.

Language boxes have the virtue that they work for any possible
language composition. However, this generality comes at a cost:
users must explicitly, and tediously, state when they want
to insert or remove language boxes. Interestingly, this is the exact
opposite of the situation with generalised parsing: language composition
authors must disambiguate each new composition anew, but users can then
freely write text in any of the languages in the composition.
The fundamental research question underlying this paper is thus whether it is
possible to extend some of the benefits of generalised parsing to language
boxes, while not losing language box's generality.
For example, in a composition of Java and SQL, where SQL is allowed
wherever a Java expression is valid, can such a system automatically insert an
appropriate SQL language box in `\texttt{for (String n: SELECT name FROM table) \{ ...
\}}'?

In this paper we present \emph{automatic language boxes}, which can
automatically insert, remove, and resize language boxes in many useful cases.
In essence, automatic language boxes are a default disambiguation mechanism
applied to any language composition. In other words, given several languages in
a composition, automatic language boxes find a non-strict subset of the
possible ambiguous parses: in many cases, only one possibility remains, and
language boxes inserted or updated as appropriate. Default disambiguation may
seem a strange choice, because it would be inappropriate in traditional batch
parsing, where disambiguation is invisible to the user, and the consequences of
an incorrect choice dire. However, in an incremental parsing setting, the
results of disambiguation are visible to the user, and the consequences of an
incorrect choice mild, since it can be simply, and permanently, overridden. The
algorithm is, in essence, comprised of several stages / heuristics: determining what user
inputs should trigger it; finding candidate language boxes to insert, remove,
or resize; filtering out those which would make the overall program worse; and
then applying the remaining candidates. Figure \ref{intro_example} shows a
simple example and walks readers through the high-level parts of the algorithm
and accompanying heuristics.

We implemented automatic language boxes as an extension to the Eco
editor~\cite{diekmann14eco}. In order to validate automatic language boxes, we
created 12 language compositions involving large, real-world languages
(Java, Lua, PHP, and SQL),
and composed programs in those compositions by extracting fragments from real-world programs.
In essence, our experiment is equivalent to opening a file
in the outer language, moving the cursor to a given position, deleting a fixed amount
of text, and then inserting text one character at a time from the inner language.
We then group the possible outcomes of such actions into `acceptable' (roughly
speaking: a language box is inserted without causing an error; or no language
box is inserted because the fragment is also valid in the outer language) and
`unacceptable' (a language box was inserted but caused an error elsewhere in
the file; or no language box was inserted despite the fragment being invalid in
the outer language). Across the \laurie{XXX} tests we ran, \validalloverall are
classified as acceptable, with the majority of those
(\laurie{completeinsertionall\%}) leading to a language box being inserted
around the entire fragment, and most of the rest (\laurie{validallnoinsert\%})
being instances of the fragment being valid in both the outer and inner
languages. We believe that this data shows that automatic language boxes
are a practical editing mechanism for language composition.
Our fully
repeatable experiment can be found at \emph{redacted for double blind review}
and our extensions to the Eco editor can be found at \emph{redacted for double
blind review}.


\section{Background}
\label{sec_background}

In this section, we briefly survey existing approaches to editing composed
programs, before giving a brief overview of incremental parsing, sufficient for
this paper's purposes.


\subsection{Delimiter-based approaches}

The traditional approach to language composition is to use delimiters
to make clear when the user has switched from one sub-language to another. The
most obvious way of achieving this is to use explicit brackets to make clear a
switch from an outer to an inner language (e.g.~`\texttt{for (String e: <<SELECT name
FROM table>>) \{ ... \}}'), though this is visually intrusive
(what~\cite[p.~4]{bravenboer05generalized} calls ``syntactic clutter``), and
prevents the
brackets being used within the sub-language (e.g.~in this case, the inner language
cannot use `\texttt{>>}' as a bit-wise operator).

Naive approaches inherit a severe restriction from traditional parsing, which
separates lexing (i.e.~the splitting of the user's input into tokens) from
parsing (i.e.~the structuring of tokens into a parse tree): all the languages
must share the same lexing rules. This restriction can be somewhat eased if the
lexer recognises the explicit brackets and extracts text between them wholesale
for separate lexing and parsing (see e.g.~\cite[p.~13-14]{tratt08domainspecific}),
though it is then hard for the lexer to accurately keep track of nested
brackets (e.g.~should brackets in comments be counted or not? and how does
one know what format comments in the inner language(s) are in?).  A
more sophisticated approach is for the lexer and parser to interact (see
e.g.~\cite{wyk07context}), such that the parse causes a switch in lexing rules
when input shifts to an inner language.
This has the advantage that brackets do not always need to be quite as visually
intrusive (e.g.~one can use a difference in keywords to identify a switch from
one language to another), though in the general case explicit brackets must still be
used to resolve ambiguities.


\subsection{Scannerless parsing}
\label{sec:scannerless}

Generalised parsing can parse any Context-Free Grammar (CFG), even those that
are ambiguous. Scannerless parsing~\cite{visser97scannerless} extends this such
that lexing and parsing are specified together. This removes the need for
explicit brackets entirely, but does so at the expense of causing many more
ambiguities (since traditional lexers implicitly resolve many ambiguities, such
as between identifiers and keywords, before parsing).
This is challenging because ambiguity is, in general,
undecidable~\cite{cantor62ambiguity} and even the best ambiguity heuristics fail
to find all possible sources of ambiguity~\cite{vasudevan13detecting}. Thus,
no matter how many static disambiguation operators one uses, in general one
cannot be sure if all possible points of ambiguity have been covered.
Furthermore, our current disambiguation operators can cause scannerless
parsers to become context-sensitive~\cite{eijck__lets_accept_rejects}, the
consequences of which remain unclear. Although it is possible in some cases
to use semantic informations such as types to aid disambiguation (see
e.g.~\cite{vinju05typedriven}), this is not applicable to all languages.


\subsection{Syntax directed editing}

Traditional syntax directed editing avoids parsing text entirely. In essence,
users edit an AST directly, with incomplete parts of a program being
represented by holes. This avoids the need for explicit delimiters, and
sidesteps issues of ambiguity completely. However, such systems are awkward to
use~\cite[p.~2]{khwaja93syntax}, for example only allowing whole nodes in the AST to be selected at a time,
and quickly fell out of fashion. The modern syntax directed editor
MPS~\cite{pech13mps} alleviates some, though not all, of these problems.
However, it requires significant expertise on the part of the language composition
author to make editing a pleasant experience, as the AST structure places
constraints on many editing operations.


\subsection{Incremental parsing}

Parsing is traditionally a batch process: an entire file is fed through a parser
and a parse tree created from it. Incremental parsing, in contrast,
continually parses text and updates a parse tree as the user types.
In this paper we make use of the incremental lexing and
LR incremental parsing algorithms of~\citet{wagner98practicalalgorithms},
taking into account the several fixes found in~\cite{diekmann18editing}.
In this subsection we provide a brief overview of this algorithm sufficient
to understand the rest of this paper.

The incremental lexer and parse both operate on the parse tree. Parse tree nodes
are either \emph{nonterminals} (representing rules in the grammar) or
\emph{tokens} (representing terminal symbols). Nonterminal nodes have an
immutable type (e.g.~`expr') but a mutable list of child nodes.
Tokens have a mutable type (e.g.~`int')
and a mutable value (e.g.~`3') but cannot have children at all.

After input from the user is received, the incremental lexer is run first.
Using lookahead information, it works out the affected area of the change,
updates or creates tokens as necessary, and marks the path from each updated or
created token to the root as changed. The incremental parser then runs,
reparsing all subtrees with changes in them, and creating or removing
nonterminals as needed.


\subsection{Language boxes}

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.35\textwidth]{images/lbox_parsetree}
\caption{An elided example of a parse tree in an incremental parser with
  language boxes: nonterminals have a type and zero or more children; terminals
  have a type (top) and a value (bottom). The composition in question is,
  again, (outer) Java and (inner) SQL. Here, the outer Java code is an
  assignment (`\texttt{type name = ...;}'). The right-hand side of the
  assignment is an SQL language box (the node with type \texttt{<sql>}): from the
  perspective of the outer Java code, the SQL node is a terminal (and hence its
  value is irrelevant). In reality, the SQL node has a complete SQL parse tree
  underneath it: the special Root, BOS (Beginning Of String), and EOS (End Of
  String) nodes that every incremental parse tree contains, as well as the actual
  SQL contents (elided to `...' in this example). }
\label{fig:lboxtree}
\end{center}
\end{figure}

Language boxes allow users users to embed one language inside another in the
context of an incremental parser. From the perspective of an outer language, a
language box is a terminal. Since
parsers care only about the type of a terminal, this is a natural fit. In
reality, language boxes do have content, though it is not visible to the outer
language: they contain a separate parse tree for the inner language within
them.

This simple definition belies its power. Consider our running Java and
SQL example composition. Java's grammar must have a reference from Java's
expression rule to a special symbol type `language box' (conventionally
represented between angle brackets to visually separate it from rules and
tokens). At run-time, if the Java parse tree has an SQL language box at the
correct point, then Java considers the tree to be syntactically correct. The
SQL language box will have its own SQL parse tree inside which may or may not
be syntactically correct. An elided example of such a tree-of-trees can be seen
in Figure~\ref{fig:lboxtree}.

Philosophically, language boxes thus form delimiters of sorts, albeit invisible
ones, between languages: from a syntactic perspective, outer languages are
ignorant of the contents of inner languages and vice versa. Thus we get much of
the power of syntax-directed editing without the accompanying difficulty of
editing ASTs. At all points, all languages can be manipulated as normal text
using the incremental parsers.


\section{The outlines of a solution}

\label{the problem}
The chief weakness of language boxes is that they must be inserted
manually by the user --- this involves pressing a special key combination,
selecting the desired inner language from a list, typing the content, and (in
general) pressing a second special key combination to complete the language box.
When language boxes are used infrequently, this is merely irritating,
but when language boxes are used frequently, it is a significant usability
issue, impeding the user's flow. Eco, an editor which supports language boxes~\cite{diekmann14eco},
slightly eases this problem by using information from the incremental parser to
highlight those languages valid at the point of the cursor,
though this is a mild palliative at best. A superior solution would be
to automatically insert, remove, and resize language boxes whenever possible.

In an ideal world, we would be able to insert language boxes exactly, and only,
when they are wanted by the user. However, this is impossible in the
general case because language composition is really grammar composition
in disguise, and thus subject to the same ambiguity problems as generalised
parsing (see Section~\ref{sec:scannerless}). Even if we were to require the
language composition author to provide a static disambiguation specification,
we cannot guarantee that it will cover all the ambiguous
possibilities. Annoying as this may be, it is a hard constraint that we cannot
change. On top of this, we also assert that a realistic solution to automatic
language boxes should satisfy several softer considerations.

First, a solution which requires language composition authors (i.e.~the people
who actually compose grammars, create code generators etc.) to provide additional
hints or commands to aid automatic language box insertion is less likely
to be used widely and/or correctly. The meta-system underlying a language
composition system is often complex, and expecting language composition authors
to be expert in every part of it (as well as the domain they are composing
languages for!) is unrealistic. For example, it can be difficult to know whether
a non-LR grammar is ambiguous or not~\cite{vasudevan13detecting} and whether
one has disambiguated it in the expected way: grammar
composition often magnifies such concerns.

Second, a solution which seriously degrades performance would be unacceptable.
For example, one simple way of finding which language boxes to insert would
be to reparse the complete file on every keypress, which would be noticeably slow for large
files. Ideally, the theoretical performance guarantees
of~\citet{wagner98practicalalgorithms} would be maintained as well as good
practical performance\footnote{Interestingly, the original implementation of
this incremental parsing algorithm had to be triggered by the user (e.g.~when
a file was saved). Modern machines are fast enough that even a naive
implementation can run comfortably on every keypress in nearly all reasonable
cases.}.

Third, a solution which inserts language boxes unpredictably would be unlikely
to find favour with users. Clearly, given the hard constraint described at the
start of this subsection, users cannot expect perfect language box insertion
all of the time. However, a reasonable minimum expectation is that it should be
entirely predictable as to when automatic language boxes are potentially
inserted, removed, or
resized; and, ideally, largely predictable as to what the effects of such
actions are. Furthermore, false negatives (i.e.~when the system inserts, removes,
or resizes language boxes incorrectly) are likely to be particularly harshly
received by users and must be reduced to the minimum possible, given the hard
constraint above.


\section{Automatic language boxes}

In this section, we present the automatic language boxes algorithm. In essence
this is a default disambiguation mechanism: given an arbitrary language
composition, it uses several heuristics to find plausible places to insert,
remove, or resize language boxes. The algorithm makes use of the fact that it
has a surrounding parse tree to provide context, and also knowledge of where
the user has recently made edits, to improve the quality of its results.

To ease the algorithms description, we start by considering the problem of language box
insertion, before then adding additional functionality (e.g.~removal and
resizing). We later validate the usefulness of automatic language boxes in
Section~\ref{sec:evaluation}.


\subsection{The consideration heuristic}

The first challenge with automatic language boxes is to decide upon a sensible
heuristic for considering if/when to insert a language box -- what we call the
\emph{consideration heuristic}. If the consideration heuristic triggers too
frequently, it will lead to too many unwanted language boxes being inserted,
each of which must then be manually removed by the user.
Conversely, if it triggers infrequently, it will not be a useful aid to the user.

We use two related observations as the guides to our consideration heuristic.
First, by definition, language composition always consists of an outer language
and one or more inner languages\footnote{Note that these terms are relative:
when we create a language box and move into it, the previously-inner language
now becomes the outer language.}. It is thus a reasonable expectation that most
text typed in the outer language is intended to be in the outer language.
Second, the clearest indication that recently typed text in the outer language
might have been intended for an inner language is that it leads to a syntax error
in the outer language.

\begin{figure}[tb]
    \includegraphics[width=.40\textwidth]{images/composition_error1.png}
    \caption{An example of a syntax error in a Java and SQL composition. In
      this example, we have turned off automatic language box insertion to
      emphasise the fact that syntax errors often occur in the middle of the
      language box we would like to insert.}
\label{fig:consideration}
\end{figure}

Our consideration heuristic therefore triggers at the point of each new syntax error.
This is an entirely predictable heuristic from a user perspective, though it
does have two consequences: the point of a syntax error is not always at the
beginning or end of the text that a user expects to be put in a language box
(see Figure~\ref{fig:consideration}); and this heuristic clearly works better
for languages whose syntaxes don't overlap a great deal. Happily, we can rely
on the fact that the incremental parser isolates syntax errors after they
occur~\cite[p.~93]{wagner98practicalalgorithms}, so that there is no
possibility of old syntax errors being considered a second time.


\subsection{The candidates heuristic}

Once the consideration heuristic has triggered, we then have to search for
plausible nodes in the parse tree at which language boxes could be inserted -- we call this the
\emph{candidates heuristic}. The trade-off here is that identifying too many
locations slows down the search and overwhelms the user with possibilities; but
identifying too few locations means that useful candidates are missed. We thus
define several sub-heuristics which we then combine together.

A candidates heuristic
can produce zero or more candidate language boxes at any given point; those
candidate language boxes may cover different spans and/or be of different
language types. Note that candidates heuristics merely need to suggest language
boxes which consume existing content: the subsequent phase in the algorithm
then determines if actually inserting such language boxes makes sense in the
wider context of the program (see Section~\ref{sec:filtering}).

Before we can define candidates heuristics, we first need to introduce the
concept of recognisers, before defining the candidates heuristics themselves.


\subsubsection{Recognisers}
\label{sec:recognisers}

\begin{figure}
\begin{lstdefault}[]
def cnds_recogniser(node, lang):
  lexer = <!\textrm{\textit{lexer for lang starting at node}}!>
  parser = <!\textrm{\textit{parser for lang}}!>
  cnds = []
  while True:
    token = lexer.next_token()
    if token is None:
      return cnds
    parser.parse_token(token)
    if parser.accepted():
      cnds.append(token.end_pos)
    elif parser.error_node.type_ != "EOS":
        return cnds
\end{lstdefault}
\caption{A generic candidates recogniser which produces the ending offsets of
  each substring starting at \texttt{node} that is valid in language
  \texttt{lang}. In essence, we create a lexer and parser for \texttt{lang}
  (lines 2--3) and then try recognising substrings that grow one token at a
  time (lines 6 and 9), though note that the recogniser parser reuses the previous
  state, so the run-time is linear. If we reach the end of the parse tree we are complete
  (lines 7--8). If we successfully parse a substring, we add a candidate to the
  list (lines 10--11). If a substring causes a parse error on anything but the
  implicit EOS (End Of String) token, we know that further input cannot fix the parse
    and terminate the search (lines 12--13).}
\label{fig:recogniser}
\end{figure}

When a candidates heuristic has identified a node $n$ in the parse tree as the
plausible start of a language box, we then have to decide if one or more
language boxes could start at that point. Although it would be possible to use
the normal incremental parser to answer this question, it would require
significant setting up and tearing down which would be tedious to program and
slow to run. Instead we provide \emph{candidates recognisers}\footnote{Some languages
  (e.g.~whitespace sensitive languages such as Python) need slightly customised
candidates recognisers.} which are able to quickly return the list of substrings valid in
a language $L$ starting at node $n$.

The main challenge for candidates recognisers is to know when to stop trying to recognise
further input. If we stop too early, we will fail to recognise valid language
boxes, but if we go too far, we will degrade performance. The technique
we use is to try recognising gradually growing substrings as valid in an inner
language, making use of the fact that the recogniser parser implicitly
reuses state from the previous token, so that the running time is linear.
If a substring is not valid, we then check where the parse failed:
if it failed on the EOS (End Of String) token, then we know that more input
would be needed to find a valid parse, so we continue the search; but if it
failed earlier than the EOS token, then we know that no further input will
fix the parse and we stop the search. Figure~\ref{fig:recogniser} shows a
more formal version of this algorithm.

For example, consider the fragment `\texttt{int x = SELECT 1 + 2;}' in our
running Java and SQL composition. If we start a candidates recogniser at the
`\texttt{SELECT}' token, we first try recognising `\texttt{SELECT}' which leads
to a syntax error at the EOS token, so we continue. We then try recognising
`\texttt{SELECT 1}', which is valid SQL, so we add it to our candidates list
and continue. `\texttt{SELECT 1 + }' errors at the EOS token, so we continue.
`\texttt{SELECT 1 + 2}' succeeds, so we add it to our candidates list.
`\texttt{SELECT 1 + 2;}' errors at the `\texttt{;}' token, so the search then
terminates, even if there is input after the fragment.


\subsubsection{The parse tree, stack, and line heuristics}

We eventually created three distinct candidates heuristics, each of which has
different strengths and weaknesses. We now describe each candidates heuristic
in detail; see Figure~\ref{lst:find_candidates} for a semi-formal version of
each.

The \emph{parse tree} candidates heuristic aims to
find plausible candidates based on the structure of the parse tree. The
intuition underlying this is that a likely point to insert a language box is
around text that forms a subtree and that we can find such points by
recursively walking the parent nodes of the node in which a syntax error was
found. However, there is a slight subtlety in that the parse tree is, by
definition, broken at the point the candidates heuristic is called. In a sense,
the incremental parser parses the tree in two stages, and the candidates
heuristic is called after the first of these, when it is possible for newly
inserted terminals to be detached from the tree~\cite[p.~58, 60]{wagner98practicalalgorithms}. Fortunately, we can solve this
easily by using the versioning feature described in ~\citet[p.~15]{wagner98practicalalgorithms}
which allows
us to view the tree as if the first stage of parsing had not yet occurred.

The \emph{stack} candidates heuristic is based on
the idea that each point in the parsing stack naturally defines a plausible
breaking point between one language and another. It walks backwards over the
parsing stack, at each point looking at the associated node. This heuristic has
two significant
advantages: the parsing stack is nearly always small, so few additional
places in the program need to be checked; and if a language box can be
inserted, parsing can continue as normal from that position in the parsing
stack. However, the weakness of this heuristic is that it tries relatively few
locations, and often misses out possibilities which seem plausible to humans.

The \emph{line} candidates heuristic captures the intuition that many language
boxes are intra-line: it searches
backwards, one node at a time, from the error node to the beginning of the line
that contains that token for candidates. This heuristic ensures that all
candidate locations close to the error node are searched, but bounds the search
in a way that is unlikely to cause a noticeable slowdown.

\begin{figure}
\begin{lstdefault}[]
def recreate_parsing_stack(lbox):
  v = global_version - 1
  path_to_lbox = set()
  parent = lbox.parent(v)
  while True:
    path_to_lbox.add(parent)
    parent = parent.parent(v)
    if parent is None:
      break

  parser = <!\textrm{\textit{initialise parser}} !>
  node = <!\textrm{\textit{root node}} !>
  while node is not lbox:
    if node in path_to_lbox:
      node = node.children(v)[0]
    else:
      parser.parse(node)
      node = node.next_lookahead()
\end{lstdefault}
\caption{An algorithm for efficiently creating a parse stack after a language box
has been inserted into the parse tree. We do this in two steps. First we
collect all the nodes on the path from the language box to the root node (lines
2--8). Second we then follow equivalent steps as when a node is marked as
changed and the incremental parser runs \cite[p.~63]{wagner98practicalalgorithms}:
we reparse all nodes up to the language box (lines 11--18), skipping
subtrees which can't be relevant to the parsing stack (lines 17--18). The
\texttt{next\_lookahead} function (line 18) returns the next node in the parse
tree in preorder. Note that we have to iterate over a previous version of the
parse tree: \texttt{node.parent(V)} and \texttt{node.children(V)} both work in
the same way e.g.~ \texttt{node.parent(\textit{V})} returns \texttt{node}'s
parent as when \texttt{node} was in version \texttt{V} (which may be
different to \texttt{node}'s parent in the current version of the tree,
\texttt{global\_version}).}
\label{fig:createparsestack}
\end{figure}

In order for later stages in the algorithm to work correctly, each candidate
needs to come with a valid parsing stack. Candidates produced by the stack
heuristic naturally come with a valid parsing stack. However, we need to create a
valid parsing stack for candidates from the parse tree and line heuristics which
requires reparsing the program. Fortunately, we can do this efficiently by
using a similar approach to that the incremental parser uses to reparse changed
nodes (see Figure~\ref{fig:createparsestack}).

\begin{figure*}[t]
\begin{minipage}[t]{0.55\textwidth}
\begin{lstdefault}[]
def parse_tree(parser, node):
  cnds = []
  v = global_version - 1
  while node is not None:
    for lang in <!\textrm{\textit{composition}}!>:
      if <!\textrm{\textit{lang can be shifted before \texttt{node.version(v)}}}!>:
        cnds.extend(cnds_recogniser(node, lang))
    node = node.parent(v)
  return cnds

def stack(parser, node):
  cnds = []
  for state, node in reversed(parser.stack):
    for lang in <!\textrm{\textit{composition}}!>:
      if <!\textrm{\textit{lang can be shifted at \texttt{state}}}!>:
        t = node.next_terminal()
        cnds.extend(cnds_recogniser(t, lang))
  return cnds

def line(parser, node):
  cnds = []
  while node.type_ not in ["BOS", "Newline"]:
    for lang in <!\textrm{\textit{composition}}!>:
      if <!\textrm{\textit{lang can be shifted before \texttt{node}}}!>:
        cnds.extend(cnds_recogniser(node, lang))
    node = node.prev_terminal()
  return cnds
\end{lstdefault}
\end{minipage}
\begin{minipage}[t]{0.44\textwidth}
  \caption{Simplified versions of our three candidates heuristics. Each is
  passed a \texttt{node}, which is the point at which an error is detected, and
finds sensible points before that node in the parse tree to be the possible
starting point of language boxes (using the candidates recogniser from
Figure~\ref{fig:recogniser}).
The \texttt{parse\_tree} candidates heuristic
walks up the parse tree to find candidate language boxes (line 6--7).
Because the parse tree is, in a sense, only partially parsed at the point the
candidates heuristic is called, we have to view the parse tree as it was before parsing
began (line 8).
The \texttt{stack} candidates heuristic walks the parse
stack, finding the node matching each point in the stack (line 13) and then
searching for candidate language boxes (line 15) starting at the first terminal
following that node (line 16).
The \texttt{line} candidates heuristic searches
backwards each token from the error node (line 26) until the beginning of
the line which contains that node (line 22) for
candidate language boxes (line 24).}
\label{lst:find_candidates}
\end{minipage}
\end{figure*}

As we shall see in Section~\ref{sec:evaluation}, each of the candidates
heuristics above has strengths and weaknesses. We therefore combine them into a
single candidates heuristic imaginatively called \emph{all} which first
attempts to find candidates using the parse tree heuristic; if that fails,
tries the stack heuristic; and if that also fails, falls back to the line heuristic.


\subsection{The filtering heuristic}
\label{sec:filtering}

Once the candidates heuristic has run, we will have zero or more possible
language boxes to insert. If there are zero candidates, then the algorithm
completes. If one or more candidates have been found, then we need to see
which of those candidates make sense in the wider context of the program --
what we call the \emph{filtering heuristic}. The challenge here is to determine
if the insertion of a language box causes further syntax errors: if it does,
the language box may not be a good candidate for insertion. Performance is
not a particular concern for the filtering heuristic as the incremental
parser will naturally inform us if inserting a language box causes syntax
errors elsewhere in the program. Rather, the main concern is that it is easy to
reject candidates because of syntax errors caused by the fact that a program
being typed is as yet incomplete (see Figure~\ref{fig:autoboxerrorafterinsert}
for an example).

\begin{figure*}[tb]
\begin{center}
\includegraphics[width=0.90\textwidth]{images/autoboxerrorafterinsert_javasql.png}
\end{center}
\begin{picture}(0,0)
    \put(-241,35.6){\textcolor{black}{\footnotesize\textbf{(a)}}}
    \put(-5,35.6){\textcolor{black}{\footnotesize\textbf{(b)}}}
\end{picture}
\vspace{-1.2em}
\caption{An example showing why parsing too far beyond a candidate language box increases
  the chances of rejecting it. In \textbf{(a)}, we have altered Eco to only insert
candidate language boxes that do not cause subsequent parse errors. However,
the `\texttt{+}` operator is invalid in an SQL \texttt{FROM} clause meaning
that it will be left to the outer language (Java) where it also causes a syntax
error. Thus the candidate language box around the SQL is rejected. In
\textbf{(b)}, we use the heuristic described in Section~\ref{sec:filtering},
where we only filter out candidate language boxes that cause syntax errors in
the first non-whitespace token. Thus although there is still a syntax error in
the program (at the `\texttt{\}}' character), since `\texttt{+}' is valid after
the candidate SQL language box, that candidate is not filtered out.}
\label{fig:autoboxerrorafterinsert}
\end{figure*}

Our filtering heuristic is thus simple: we accept all candidate language
boxes which do not lead to a syntax error at the next non-whitespace token. In other
words, if a language box is syntactically valid at its immediate surrounding
context in the parse tree, we don't mind if it causes errors beyond that
context, since we assume those are the result of an
incomplete program. Note that, by definition, the tokens before the candidate
language box will be valid, so we only need to check those tokens after the
candidate. The reason that we specify that the first non-whitespace
token must not contain an error is that grammars for incremental parsing almost
always define whitespace as a token. This means that the incremental parser
often inserts a whitespace token after a candidate language box, and that
whitespace token is by definition syntactically valid, though not particularly
insightful. We thus need to skip such tokens in order to get to a
token which tells us something useful about the context surrounding a candidate
language box.


\subsection{Applying or presenting candidates}
\label{applying and presenting}

Once the filtering heuristic has run, we will have zero or more possible
language boxes to insert. If there are zero candidates, then the algorithm
completes. If there is one candidate, we simply insert it to the user's
program. If the user is unhappy with the insertion, they can remove it by
pressing undo (conventionally \keys{Ctrl+Z}). Implemented naively, this isn't
enough, as on each subsequent key press the algorithm may try to insert the
same unwanted language box. Therefore removing a language box in this way marks
a flag \texttt{noinsert} on the node with a syntax error identified by the
consideration heuristic. When set to \texttt{true}, the candidates heuristic
will notice and deliberately ignore such nodes so that language boxes are not
repeatedly inserted.

\begin{figure*}
\begin{center}
\includegraphics[width=1\textwidth]{images/autobox_multioption_java_sql.png}
\end{center}
\begin{picture}(0,0)
    \put(-254,96){\textcolor{black}{\footnotesize\textbf{(a)}}}
    \put(3,96){\textcolor{black}{\footnotesize\textbf{(b)}}}
    \put(-254,53){\textcolor{black}{\footnotesize\textbf{(c)}}}
    \put(3,53){\textcolor{black}{\footnotesize\textbf{(d)}}}
\end{picture}
\vspace{-1.7em}
\caption{An example of multiple language box candidates in our running Java and SQL
  composition. \textbf{(a)} The user is editing an existing Java programme,
  and has just deleted the expression after \qtt{remote}.
  \textbf{(b)} Inserting an SQL statement leads a syntax error in Java. The
  automatic language box algorithm then finds multiple valid language box
  candidates. Rather than picking one at random, the syntax error remains, and
  the existence of multiple candidates is indicated to the user by the light
  bulb image.
  \textbf{(c)} Clicking on the light bulb displays the candidate language boxes
  that could be inserted. In this example, the user clicks on the first in the
  drop-down list. \textbf{(d)} The appropriate language box is inserted.}
\label{fig:multiplecnds}
\end{figure*}

\label{multiple candidates}
However, if there are multiple candidates, then we have two choices: we could
insert one of the candidates and present the others to the users as choices; or
simply present all the candidates as choices without inserting
any of them. The former approach is surprisingly hard to do well. If we were to
non-deterministically select one candidate and insert it, the user would be
unable to predict what was about to happen on each key press. We could instead
rank candidates (perhaps by `relevance', or length, or starting position etc.),
but we were unable to find a ranking system which matches the user's intentions
often enough to be worthwhile. We therefore simply present all the candidates
as options to the user from which they must choose one (see Figure~\ref{fig:multiplecnds}). As we shall see in
Section~\ref{sec:evaluation}, this happens rarely enough that it is not a
significant problem. It is also worth noting that this is an
example of a fundamental difference between traditional batch parsing and
incremental parsing: it is entirely feasible for us
to ask the user for their help in choosing language boxes as that choice can
be made once and recorded permanently, rather than having to be made anew
on each (batch) parse.


\begin{center}
\end{center}


\subsection{Removing and resizing}

Automatically inserted language boxes start life in the \emph{uncommitted}
state, which means that they can then be considered possible candidates for
automatic removing and resizing. Language boxes move to the \emph{committed}
state when the user shows that they have finished
editing at the current point by moving the cursor outside of the language box.
Users can manually change a committed box to uncommitted if they
later want it to be subject to the algorithm again. If the content of an
uncommitted language box, or its surrounding area, changes then it may be
automatically removed or resized by the algorithm.


\subsubsection{Removing}
\label{sec:removing}

The simplest example of when we might want an automatic language box to be removed is if
the user deletes a character immediately after an automatic language box has
been inserted. For example, if an SQL language box is inserted as soon as the
user types `\texttt{int x = SELECT * FROM t}` and the user then presses
backspace, the automatic language box should disappear because `\texttt{SELECT
* FROM}' is valid Java and we want to prioritise the outer language in a
composition (see Figure~\ref{fig_autoremoval}). The full set of situations that
we handle is as follows:

\begin{enumerate}
  \item If an uncommitted language box's content causes a syntax error within
    the language box, then the language box should be removed if its contents
    can be successfully parsed in the outer language.
  \item If an uncommitted language box becomes part of a syntax error in the outer
    language then it should be removed if its contents are valid in the
    outer language.
  \item If an uncommitted language box's content is valid in both the inner and
    outer languages, then the language box should be removed if that would not
    then cause subsequent parse errors. Following the precedent from
    Section~\ref{sec:filtering}, we use the first non-whitespace token after
    the language box as a proxy for this.
\end{enumerate}

Note, that while the first two situations are triggered by an error occuring either inside
the box or on the box itself, the third situation has no clear trigger. On each
run of the incremental parser we thus check the third situation for each uncommitted
language box in the program. Fortunately, unless the user has manually marked some
language boxes as uncommitted, the only uncommitted language boxes can be in
the location of the cursor, so their number is typically small and the performance
implications trivial.

\begin{figure*}
\begin{center}
\includegraphics[width=0.70\textwidth]{images/auto_remove_java_sql.png}
\begin{picture}(0,0)
    \put(-375,5.5){\textcolor{black}{\textbf{(a)}}}
    \put(-175,5.5){\textcolor{black}{\textbf{(b)}}}
\end{picture}
\vspace{-0.8em}
\end{center}
\caption{An example showing the automatic language box removal in practice.
\textbf{(a)} The user has meant to write a Java expression, but has forgotten
the second \qtt{*} after \qtt{from}, which has resulted in a language box
being inserted.
\textbf{(b)} Since uncommitted language boxes can be automatically removed
again, the user doesn't need to revert the accidental language box
themselves. Instead they can just fix their mistake inside of the box,
which will remove it, since its content is now invalid in the SQL box, but
valid the outer Java.}
\label{fig_autoremoval}
\end{figure*}


\subsubsection{Resizing}

Although we do not change the starting position of uncommitted language boxes
(which can be highly distracting), their right hand extent can be automatically
changed to encompass more or less content (Figure~\ref{intro_example} shows an
example of the former). A language boxes is expanded to encompass more content
if: its parse tree does not contain a syntax error; if encompassing the
additional content does not cause a syntax error within the language box; and
if removing the content from the outer language does not cause syntax errors in
the first non-whitespace token in the outer language.
Language boxes are shrunk to encompass less content if they
contain a syntax error and moving the content to the outer language both
fixes the error inside the language box and does not
introduce additional syntax errors in the outer language.

Both growing and shrinking can be handled with our existing
candidates recogniser (see Section~\ref{sec:recognisers}).
While there is a clear indicator for when a language box may need to be shrunk
(e.g.~when it contains an error), this is not the case for expansion. We
must therefore run our altered candidates recogniser at the start of
each uncommitted language box; fortunately, as in automatic language box
removal (see Section~\ref{sec:removing}), there are almost never enough of
these to cause performance concerns. The candidates recogniser
returns all the possible right hand extents of the language box. Starting
from the candidate which matches the most content and working backwards, we then
filter out candidates which do not meet the above conditions. If none remain,
the algorithm completes; if one remains,
we resize the language box appropriately; if more than one remains, we present
the multiple options to the user in the same way as in Section~\ref{multiple candidates}.


\subsection{Highly ambiguous compositions}
\label{sec:highly ambiguous compositions}

Some language compositions are so fundamentally ambiguous that normal automatic
language boxes do not work well. For example, consider a composition of Java
(or any other programming language!) with HTML, where HTML language boxes can
be used wherever Java expressions are valid. Since HTML's lexer can match
almost any text, nearly all errors in Java can be resolved by wrapping text in
an HTML language box, which is unlikely to match the user's intentions.

To help with such cases, we thus have to relax the `no hints' constraint from
Section~\ref{the problem} by allowing language composition authors to specify
either the valid or the invalid token types which can appear at the start of
a language box. For example, in the case of the Java and HTML composition, a
good choice is to specify HTML tags as being the only valid starting token
types for a candidate language box. Any such hints given by language composition authors
are checked in the candidates recogniser so that inappropriate candidates do
not cause pointless work in later stages of the algorithm.


\section{Limitations}
\label{sec:lbox_limitations}

Since automatic language boxes are a default disambiguation mechanism,
there are inevitably situations where they do not perform as well as hoped.
Although (as we shall see in Section~\ref{sec:evaluation}) these cases are
rare, it is useful to enumerate some of their fundamental weaknesses.

Although our solution to highly ambiguous compositions (see Section~\ref{sec:highly
ambiguous compositions}) works well when the outer language matches specific
input (e.g.~Java) and the inner language matches nearly anything (e.g.~HTML),
the reverse does not hold. For example, if we compose HTML and Java where
Java expressions are valid wherever HTML tags are valid, automatic language
boxes almost never trigger, since there are few ways of making a syntax error
in HTML. The only way this can be solved is by using a consideration
heuristic which is not triggered by syntax errors, but it is not clear to
us what a sensible alternative might be.

Lexical ambiguities between languages can also cause subtle problems. For
example, imagine that we compose Java and Lua, such that Lua expressions are
valid wherever Java expressions are valid and then input `\texttt{int x = 3 //
4 + 1;}'. This leads to a syntax error at the beginning of the line following
this statement and no automatic language boxes are inserted. However, this is
confusing for users, since `\texttt{//}' is Lua's integer division operator,
and they might reasonably expect a Lua language box to be put around `\texttt{3
// 4}' and/or `\texttt{3 // 4 + 1}'. However, since \texttt{//} is the Java
comment prefix, `\texttt{// 4 + 1;}' is ignored entirely. Since the resulting
syntax error is thus forced onto the following line, this means that not even
the line candidates heuristic can find a starting point for language boxes that
matches a human's intuition. Fortunately, such ambiguities happen
rarely.

Automatic language boxes inherit incremental parsing's weaknesses on multiline
comments and strings. For example, in a naive Java grammar, typing
`\texttt{/*}' without the matching `\texttt{*/}' causes the entire rest of the
file (whether it is inside or outside a language box) to be relexed and tokens
flattened. Interestingly, a slight variant on language boxes solves this problem
for incremental parsing \cite[p.~108--122]{diekmann18editing}.
However, this is not applicable to our situation, where candidates
recognisers may end up lexing until the end of the file. Fortunately, this is
unlikely to be a performance problem in practice. First, this can only happen
if an inner language has sufficient lexical overlap with the outer language
(e.g.~sharing the same syntax for comments) and the rest of a file matches both
language's lexing rules.  Second, lexing is a fast activity in general and
particularly fast in the recogniser because we are not altering the parse tree
in any way.


\section{Evaluation}
\label{sec:evaluation}

To evaluate the efficacy of automatic language boxes, a large-scale experiment
is necessary. We first present our methodology before looking at the results of
our experiment.


\subsection{Methodology}

Since there is no equivalent work that we know of, we have to
define our own methodology.

First, in order to produce numbers that are plausibly representative of situations
that real users might encounter, we created 12 language compositions of
real-world languages, and created \totalinsertions tests from real-world
programs. Each test is a tuple (\emph{base file}, \emph{base file function
definition or expression offset}, \emph{base file function definition or
expression span}, \emph{function definition or expression fragment}) where
`base file' is an instance of the outer language in the composition and
`fragment' is an instance of the inner language. For each test, we then loaded
\emph{base file} into our extension of Eco; emulated key presses which move the
cursor to the \emph{offset} and deleted \emph{span} characters; and then
emulated key presses which inserted \emph{fragment}. For each test we recorded
\laurie{this will need updating} whether a language box was inserted or not, if
the insertion lead to a valid or invalid program, and if it didn't for what
reason (i.e.~a wrong language box was inserted; no candidate was found; or
multiple candidates were found).

Second, we need to classify the outcome of each test. The overall question we
want an answer to is: do automatic language boxes work well in most
cases? Answering this is not completely trivial, because there are several
possible outcomes from inserting text in an inner language. We have chosen to
break these down into six categories:

\begin{description*}
  \item[Complete insertion] A language box was automatically inserted around
    all of the inner fragment.
  \item[Partial insertion (no errors)] A language box was automatically
    inserted around part of the inner fragment, and the resulting text that was left
    in the outer language did not cause any errors.
  \item[Partial insertion (errors)] A language box was automatically inserted
    around part of the inner fragment, but the resulting text that was left
    in the outer language caused one or more syntax errors later in the file.
  \item[No insertion (valid)] No language box was automatically inserted because
    the fragment was valid in the outer language.
  \item[No insertion (errors)] No language box was automatically inserted even
    though the fragment was not valid in the outer language.
  \item[No insertion (multi)] No language box was automatically inserted because
    there were multiple possible candidates.
\end{description*}

We then group these into `acceptable' -- complete insertion, partial insertion
(no errors), no insertion (valid), and no insertion (multi) -- and
`unacceptable' -- partial insertion (errors), no insertion (errors) -- groups.
If automatic language boxes are to be useful, we would need to see a high value
for the acceptable group and a low value for the unacceptable group.


\subsubsection{Language compositions}

To create our 12 language compositions, we used the grammars of 4 real-world
languages (Java 5, Lua 5.3, PHP 5.6, and SQLite 3.27).
For each language composition of $L_1$ (outer) and $L_2$ (inner), we allow
expressions and function definitions in $L_2$ to be used wherever expressions
and function definitions in $L_1$ are normally valid. For example, in the
composition \emph{JavaLua}, Java is the outer language and Lua the inner
language: Lua function definitions and expressions can be used wherever Java
function definitions and expressions (respectively) are valid. The one exception
to this is when SQL is the inner language: since our corpus consists of SQL
statements, it makes little sense to allow SQL statements where a Java/Lua/PHP
function is valid. In this case, we restrict the composition to only insert SQL
statements where Java/Lua/PHP expressions are valid (i.e.~we do not insert
function definitions at all). The
particular language compositions we created can be seen as the $x$-axis labels
in Table~\ref{tbl:valid}.


\subsubsection{Program corpus}

We then collected a corpus of inputs in each language.
For PHP, we used the source code of Wordpress 4.6.13, which consists of 365 files that are
valid when parsed with our PHP grammar, which total 173,368 LoC after we
have stripped out the embedded HTML which is not part of the PHP
language as such. For Java, we used the Java Standard Library 5 which consists
of 6,556 files and 424,051 LoC.
For Lua, we used Lua's test suite, which consists of 32 files totalling 13,990 LoC.
For SQL, we used SQLite's test suite, consisting of 1,100 test files which
contain 27,526 tests totalling 89,211 LoC.

We then ran each file in the corpus through a parser to identify the offsets and spans
of function definitions and expressions, collecting the longest match when an
expression contained several subexpressions. \laurie{do we have macros for these numbers?}Overall, we identified 2,474
expressions and 518 functions for PHP, 52,687 expressions and 6,743 functions for
Java, 4,476 expressions and 230 functions for Lua, and 36,017 statements for SQL.
Some of the expression numbers, e.g.~PHP, may seem small considering the amount
of files they were extracted from. This is because we only extracted
expressions from assignments, because they are more likely to contain complex
expressions, whereas expressions in function calls or array initialisations are
typically single value strings, numbers, or variable names and thus rarely lead
to the insertion of a language box.\lukas{Currently only for PHP, Java}


\subsection{Results}

\begin{table*}[tb]
    \input{tables/tbl_valid.tex}

    \vspace{7pt}
    \caption{The total percentage of acceptable outcomes for each benchmark and
    heuristic. Acceptable outcomes are that: a valid automatic language box
    was inserted; no language box was inserted since the inserted fragment
    was also valid in the outer language; the insertion had multiple options
    which are presented to the user. In other words, the total percentage
    doesn't include invalid insertions of language boxes and errors for which
    no language box could be found automatically.}
    \label{tbl:valid}
\end{table*}

\begin{table*}[tb]
    \input{tables/tbl_breakdown.tex}

    \vspace{7pt}
    \caption{Overall performance of the different
    heuristics on all benchmarks per outcome category. The categories are:
    \textbf{Valid insertion}, a language box was successfully inserted, \textbf{Invalid insertion},
    a language box was inserted but it did not fix the error or introduced new
    ones, \textbf{No insertion (Valid)}, no language box was inserted because the inserted
    code fragment is valid syntax, \textbf{No insertion (Error)}, no language box could be
    found to fix the error, \textbf{No insertion (Multi)}, multiple language box options
    were found.}
    \label{tbl:breakdown}
\end{table*}

We break the results of our experiment down in two ways: by acceptable results
per language composition (Table~\ref{tbl:valid}); and by outcome in the
overall benchmark suite (Table~\ref{tbl:breakdown}). Appendix~\ref{apdx:tables}
contains several tables which give a more detailed breakdown of information
that is, in a sense, a combination of that between Tables~\ref{tbl:valid}
and~\ref{tbl:breakdown}.

In both cases we show
the differences in the various candidates heuristics, which shows that while
each has some language compositions where it performs poorly, when combined
together they perform well across all 12 language compositions.

Table \ref{tbl:valid} shows the total percentage of
acceptable outcomes for each heuristic used broken down by each composition.
Acceptable outcomes are one of the following: a language box gets successfully
inserted; no language box was inserted since the insertion was already valid in
the outer language; the insertion had multiple options which are presented to
the user.

The results show that while each heuristic has weaknesses, when put together
they result in over 96\% of acceptable outcomes. Weaknesses in the heuristics
are based on the composition. For example, the parse-tree-based heuristic only
achieves 67\% of acceptable outcomes when used on the Java+Lua composition. The
reason for this low number can be accounted to the insertion of Lua functions
right after a Java comment.  Since the insertion is attached to the comment
subtree, the parse-tree-based heuristic is not able to find a valid location for
the language box by traversing the parse tree.  The line-based heuristic on the
other hand has difficulties with the composition of Java+PHP. The reason for
this is that PHP's function syntax is similar to Java's, e.g.~\texttt{function
x() \{\}} is a valid Java function, where \texttt{function} represents a type.
This leads to many errors only occurring in one of the following lines, which
the line-based heuristic can not deal with. The stack-based heuristic also has
a weakness with the composition of Lua+SQLite. The problem here is related to
the way Lua parses certain inputs. For example, when composing \texttt{x =
SELECT a, b FROM t}, everything up to `\texttt{b}' can be parsed in Lua,
leading to a reduction. This reduction removes \texttt{SELECT} from the stack,
replacing it with a subtree and making it impossible to find a valid location
to insert a language box at.


\subsection{Threats to validity}

There are two overall threats to validity in our evaluation.

First, it is possible that our suite of language compositions and corpus of
programs are unrepresentative. We have reduced these chances somewhat by using
4 real-world programming languages and a fairly large number of well-known
programs written in those languages, but of course it is possible to compose
very different styles of languages, and to compose them in very different ways.

Second, we have made various claims about performance in this paper, but Eco is
a poor vehicle for evaluating them: it is written in Python, a relatively
slow language; and Eco's choice of data-structures
was designed for flexibility, not efficiency . For example, nodes in Eco's
parse tree are very heavy weight (with a base size of around 2KiB, which grows
rapidly as undo history is added), and do not include any of the optimisations
described in~\citet{wagner98practicalalgorithms} (which would approximately reduce the
base size to a tenth of its current size and substantially reduce the costs of
additional undo history). Despite that, \laurie{what i'd hope to say here
is something like ``the slowest time to insert was XXXs which isn't too bad''.}
\lukas{this is going to be difficult. The last run we did had Min: 0.0004s, Max: 792s, Avg: 0.58s. The reason
for this high number is that PHP compositions often relex the entire file when opening strings. Until
the string is closed, each keypress lexes the whole file, and some insertions have strings with 100 characters
that are typed one char at a time. There is also an unfortunate problem with wagner's error recovery,
which results in automatic language boxes being triggered multiple times on the same error,
while error recovery is trying to find an isolation tree (tho this we can probably fix)}
\laurie{i guess those times are the length of time for the whole fragment to be inserted?
because it now occurs to me that what we probably care about is the maximum
length of time for any given keypress. i suppose we can guesstimate this by
dividing the time per file by the number of characters, but that might hide
outliers.}


\section{Conclusions}

\laurie{XXX}

\begin{acks}
This research was funded by the EPSRC Lecture (EP/L02344X/1) fellowship.
\end{acks}


\bibliography{bib}

\clearpage
\appendix

\section{Tables}
\label{apdx:tables}

In this appendix, we show detailed outcomes by candidates heuristic, in
similar fashion to Table~\ref{tbl:breakdown}.
\lukas{update this to show the same outcomes as in Table 2}


\begin{table*}[b]
\input{tables/tbl_bench_all.tex}
\caption{The \emph{all} candidates heuristics}
\end{table*}

\begin{table*}[b]
\input{tables/tbl_bench_hist.tex}
\caption{The \emph{parse tree} candidates heuristics}
\end{table*}

\begin{table*}[b]
\input{tables/tbl_bench_stack.tex}
\caption{The \emph{stack} candidates heuristics}
\end{table*}

\begin{table*}[b]
\input{tables/tbl_bench_line.tex}
\caption{The \emph{line} candidates heuristics}
\end{table*}


\end{document}
